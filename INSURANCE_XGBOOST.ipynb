# xgboost
#Insurance policy and those who qualify for it
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# Importing data sets
dataset_train = pd.read_csv("train_data.csv")
dataset_test = pd.read_csv("test_data.csv")

X_train = dataset_train.iloc[:, 1:11].values

y_train = dataset_train.iloc[:, 13].values
X_test = dataset_test.iloc[:, 1:11].values
dataset_train.columns
# Fixing the missing data, using mean of each column.
from sklearn.impute import SimpleImputer

#WORKING ON THE DUMMY VARIABLE - MISSING VALUE
missingvalues_1 = SimpleImputer(missing_values=np.nan, strategy="most_frequent", verbose=0)
missingvalues_train_1 = missingvalues_1.fit(X_train[:,[5]])
rows_3 =np.array(missingvalues_train_1.transform(X_train[:,[5]]))

missingvalues = SimpleImputer(missing_values=np.nan, strategy="mean", verbose=0)
# X_train missing values
missingvalues_train = missingvalues.fit(X_train[:,[7, 9]])
rows =np.array(missingvalues_train.transform(X_train[:,[7,9]]))


row_1 = rows[:,0]
row_2 = rows[:,[1]]
# Removing the columns that was having the missing values
df = pd.DataFrame(X_train)
# Adding the columns back
df[5]=rows_3
df[7]= row_1
df[9]=row_2
X_train = df

# X_test missing values
missingvalues_test_1 = SimpleImputer(missing_values=np.nan, strategy="most_frequent", verbose=0)
missingvalues_test_1 = missingvalues_1.fit(X_test[:,[5]])
test_row_3 =np.array(missingvalues_test_1.transform(X_test[:,[5]]))

missingvalues = SimpleImputer(missing_values=np.nan, strategy="mean", verbose=0)
missingvalues_test = missingvalues.fit(X_test[:,[9]]) 
test_row = np.array(missingvalues_test.transform(X_test[:,[9]]))

# Removing the column that was having the missing values
df_test = pd.DataFrame(X_test)
# Adding the columns back
df_test[5]= test_row_3
df_test[9]= test_row
X_test = df_test

#Index model
#X_train =pd.DataFrame(X_train,row_1)

# taking dummy variables

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
LE = LabelEncoder()
X_train[3] = LE.fit_transform(X_train[3])
X_train[4] = LE.fit_transform(X_train[4])
X_train[5] = LE.fit_transform(X_train[5])
X_train[6] = LE.fit_transform(X_train[6])

X_test[3] = LE.fit_transform(X_test[3])
X_test[4] = LE.fit_transform(X_test[4])
X_test[5] = LE.fit_transform(X_test[5])
X_test[6] = LE.fit_transform(X_test[6])

# Feature Scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)

#PART 2
import xgboost as xgb
from xgboost import XGBClassifier 
classifier = XGBClassifier()
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)

y_pred_prob = classifier.predict_proba(X_test)
from sklearn.metrics import confusion_matrix
#cm = confusion_matrix(y_test,y_pred)

import joblib
model_file = open("models/xgb_model.pkl","wb")
joblib.dump(classifier,model_file)
model_file.close()

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator=classifier, X= X_train, y = y_train, cv=10) 
accuracies.mean()
accuracies.std()